{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69e236db",
   "metadata": {},
   "source": [
    "# Demonstration of Web Scraping using different Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a17bff",
   "metadata": {},
   "source": [
    " ## 1. Demonstration of Web Scraping using BeautifulSoup Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58cd75a",
   "metadata": {},
   "source": [
    "### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "335eb771",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095993c5",
   "metadata": {},
   "source": [
    "**In this step We are scraping data from market watch webstie using Beautifulsoup library.**\n",
    "\n",
    "\n",
    "**The data we scraped is Canoo's financial statemenet data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3afd7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.marketwatch.com/investing/stock/goev/financials?mod=mw_quote_tab\"\n",
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.text, 'lxml')\n",
    "\n",
    "table = soup.find('table',class_='table table--overflow align--right')\n",
    "\n",
    "rows = table.find('tbody',class_='table__body row-hover').find_all('tr')\n",
    "\n",
    "with open(\"canoo_financial_statement.csv\", \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Write header\n",
    "    writer.writerow([\"Key_factors\", \"2018\", \"2019\", \"2020\", \"2021\",'2022','5_year'])\n",
    "\n",
    "    for i in rows:\n",
    "        td_row = i.find_all('td')\n",
    "        data = []\n",
    "        for z in td_row:\n",
    "            f_row = z.find_all('div',class_=\"cell__content\")[0]\n",
    "            data.append(f_row.get_text(strip=True))\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cd3268",
   "metadata": {},
   "source": [
    "### 2. Data scraping using Pandas library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afc4746",
   "metadata": {},
   "source": [
    "**Using pandas read_html method we can read the data of web page, then we can convert it in pandas Dataframe or can store in csv fiel**\n",
    "\n",
    "**These method useful in scraping the text data that present on the page**\n",
    "\n",
    "**For Dynamic websites and multiple pages we have other methods for it**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9ffb51",
   "metadata": {},
   "source": [
    "**For Eg. here is a canoo's insider activity of share buy/sell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db44c303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>shares traded</th>\n",
       "      <th>shares held</th>\n",
       "      <th>Price</th>\n",
       "      <th>type (sell/buy)</th>\n",
       "      <th>option</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ruiz Hector M.</td>\n",
       "      <td>02/06/2024</td>\n",
       "      <td>745.0</td>\n",
       "      <td>283355.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>Sell</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MURTHY RAMESH</td>\n",
       "      <td>01/23/2024</td>\n",
       "      <td>1217.0</td>\n",
       "      <td>283669.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>Sell</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ruiz Hector M.</td>\n",
       "      <td>01/03/2024</td>\n",
       "      <td>3444.0</td>\n",
       "      <td>284100.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>Sell</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ruiz Hector M.</td>\n",
       "      <td>01/01/2024</td>\n",
       "      <td>912.0</td>\n",
       "      <td>287544.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Sell</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MURTHY RAMESH</td>\n",
       "      <td>12/25/2023</td>\n",
       "      <td>205.0</td>\n",
       "      <td>281886.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>Sell</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ethridge Greg</td>\n",
       "      <td>12/19/2023</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>1947419.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Buy</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sheeran Josette</td>\n",
       "      <td>11/19/2023</td>\n",
       "      <td>22484.0</td>\n",
       "      <td>1313975.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>Sell</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MURTHY RAMESH</td>\n",
       "      <td>11/19/2023</td>\n",
       "      <td>527.0</td>\n",
       "      <td>282091.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>Sell</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>von Storch Debra</td>\n",
       "      <td>11/08/2023</td>\n",
       "      <td>326051.0</td>\n",
       "      <td>419310.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Buy</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Schmueckle Rainer</td>\n",
       "      <td>11/08/2023</td>\n",
       "      <td>326051.0</td>\n",
       "      <td>419310.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Buy</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chiang Foster</td>\n",
       "      <td>11/08/2023</td>\n",
       "      <td>326051.0</td>\n",
       "      <td>419310.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Buy</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DATTILO THOMAS A</td>\n",
       "      <td>11/08/2023</td>\n",
       "      <td>326051.0</td>\n",
       "      <td>509310.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Buy</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KINGSBURY ARTHUR F</td>\n",
       "      <td>11/08/2023</td>\n",
       "      <td>326051.0</td>\n",
       "      <td>419310.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Buy</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Romo Edelman Claudia</td>\n",
       "      <td>11/08/2023</td>\n",
       "      <td>326051.0</td>\n",
       "      <td>419310.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Buy</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MURTHY RAMESH</td>\n",
       "      <td>11/06/2023</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>282618.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>Sell</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MURTHY RAMESH</td>\n",
       "      <td>10/01/2023</td>\n",
       "      <td>2707.0</td>\n",
       "      <td>283619.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>Sell</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ruiz Hector M.</td>\n",
       "      <td>10/01/2023</td>\n",
       "      <td>2814.0</td>\n",
       "      <td>285456.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>Sell</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sheeran Josette</td>\n",
       "      <td>08/20/2023</td>\n",
       "      <td>25052.0</td>\n",
       "      <td>1336459.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>Sell</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MURTHY RAMESH</td>\n",
       "      <td>08/20/2023</td>\n",
       "      <td>577.0</td>\n",
       "      <td>283326.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>Sell</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Aquila Tony</td>\n",
       "      <td>08/03/2023</td>\n",
       "      <td>5599104.0</td>\n",
       "      <td>79986536.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Buy</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MURTHY RAMESH</td>\n",
       "      <td>07/17/2023</td>\n",
       "      <td>992.0</td>\n",
       "      <td>283903.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>Sell</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Manget Kenneth</td>\n",
       "      <td>07/05/2023</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Buy</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Manget Kenneth</td>\n",
       "      <td>07/05/2023</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>Buy</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MURTHY RAMESH</td>\n",
       "      <td>07/04/2023</td>\n",
       "      <td>2394.0</td>\n",
       "      <td>284895.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>Sell</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Ruiz Hector M.</td>\n",
       "      <td>07/04/2023</td>\n",
       "      <td>2490.0</td>\n",
       "      <td>284962.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>Sell</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name        Date  shares traded  shares held  Price  \\\n",
       "0         Ruiz Hector M.  02/06/2024          745.0     283355.0   0.16   \n",
       "1          MURTHY RAMESH  01/23/2024         1217.0     283669.0   0.18   \n",
       "2         Ruiz Hector M.  01/03/2024         3444.0     284100.0   0.23   \n",
       "3         Ruiz Hector M.  01/01/2024          912.0     287544.0   0.25   \n",
       "4          MURTHY RAMESH  12/25/2023          205.0     281886.0   0.24   \n",
       "5          Ethridge Greg  12/19/2023      1500000.0    1947419.0    NaN   \n",
       "6        Sheeran Josette  11/19/2023        22484.0    1313975.0   0.32   \n",
       "7          MURTHY RAMESH  11/19/2023          527.0     282091.0   0.32   \n",
       "8       von Storch Debra  11/08/2023       326051.0     419310.0    NaN   \n",
       "9      Schmueckle Rainer  11/08/2023       326051.0     419310.0    NaN   \n",
       "10         Chiang Foster  11/08/2023       326051.0     419310.0    NaN   \n",
       "11      DATTILO THOMAS A  11/08/2023       326051.0     509310.0    NaN   \n",
       "12    KINGSBURY ARTHUR F  11/08/2023       326051.0     419310.0    NaN   \n",
       "13  Romo Edelman Claudia  11/08/2023       326051.0     419310.0    NaN   \n",
       "14         MURTHY RAMESH  11/06/2023         1001.0     282618.0   0.26   \n",
       "15         MURTHY RAMESH  10/01/2023         2707.0     283619.0   0.49   \n",
       "16        Ruiz Hector M.  10/01/2023         2814.0     285456.0   0.49   \n",
       "17       Sheeran Josette  08/20/2023        25052.0    1336459.0   0.43   \n",
       "18         MURTHY RAMESH  08/20/2023          577.0     283326.0   0.43   \n",
       "19           Aquila Tony  08/03/2023      5599104.0   79986536.0    NaN   \n",
       "20         MURTHY RAMESH  07/17/2023          992.0     283903.0   0.70   \n",
       "21        Manget Kenneth  07/05/2023      1500000.0    1500000.0    NaN   \n",
       "22        Manget Kenneth  07/05/2023      1500000.0    1500000.0   0.52   \n",
       "23         MURTHY RAMESH  07/04/2023         2394.0     284895.0   0.55   \n",
       "24        Ruiz Hector M.  07/04/2023         2490.0     284962.0   0.55   \n",
       "\n",
       "   type (sell/buy) option  \n",
       "0             Sell     No  \n",
       "1             Sell     No  \n",
       "2             Sell     No  \n",
       "3             Sell     No  \n",
       "4             Sell     No  \n",
       "5              Buy     No  \n",
       "6             Sell     No  \n",
       "7             Sell     No  \n",
       "8              Buy     No  \n",
       "9              Buy     No  \n",
       "10             Buy     No  \n",
       "11             Buy     No  \n",
       "12             Buy     No  \n",
       "13             Buy     No  \n",
       "14            Sell     No  \n",
       "15            Sell     No  \n",
       "16            Sell     No  \n",
       "17            Sell     No  \n",
       "18            Sell     No  \n",
       "19             Buy     No  \n",
       "20            Sell     No  \n",
       "21             Buy     No  \n",
       "22             Buy     No  \n",
       "23            Sell     No  \n",
       "24            Sell     No  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_html(\"https://markets.businessinsider.com/stocks/goev-stock?miRedirects=1#insider_activity\")[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5ce56d",
   "metadata": {},
   "source": [
    "**canoo's competitors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f32a679c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock Name</th>\n",
       "      <th>Stock Price</th>\n",
       "      <th>52 Week High</th>\n",
       "      <th>52 Week Low</th>\n",
       "      <th>Capital</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.css-1knbux5{display:-webkit-box;display:-webk...</td>\n",
       "      <td>$ 19.93</td>\n",
       "      <td>$ 71.50</td>\n",
       "      <td>$ 15.28</td>\n",
       "      <td>Large Cap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Proterra Inc</td>\n",
       "      <td>$ 4.20</td>\n",
       "      <td>$ 9.20</td>\n",
       "      <td>$ 3.48</td>\n",
       "      <td>Small Cap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nikola Corporation</td>\n",
       "      <td>$ 1.51</td>\n",
       "      <td>$ 11.87</td>\n",
       "      <td>$ 1.51</td>\n",
       "      <td>Small Cap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Stock Name Stock Price 52 Week High  \\\n",
       "0  .css-1knbux5{display:-webkit-box;display:-webk...     $ 19.93      $ 71.50   \n",
       "1                                       Proterra Inc      $ 4.20       $ 9.20   \n",
       "2                                 Nikola Corporation      $ 1.51      $ 11.87   \n",
       "\n",
       "  52 Week Low    Capital  \n",
       "0     $ 15.28  Large Cap  \n",
       "1      $ 3.48  Small Cap  \n",
       "2      $ 1.51  Small Cap  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_html(\"https://scripbox.com/us-stocks/goev-share-price\")[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7aa6445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SYMBOL</th>\n",
       "      <th>LAST</th>\n",
       "      <th>CHG</th>\n",
       "      <th>%CHG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AYROAYRO Inc</td>\n",
       "      <td>1.7900</td>\n",
       "      <td>-0.0200</td>\n",
       "      <td>-1.10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FFIEFaraday Future Intelligent Electric Inc</td>\n",
       "      <td>0.0945</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>+0.8538%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FUVArcimoto Inc</td>\n",
       "      <td>0.6298</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>+1.597%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MULNMullen Automotive Inc</td>\n",
       "      <td>8.0700</td>\n",
       "      <td>-1.0600</td>\n",
       "      <td>-11.61%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FSRFisker Inc</td>\n",
       "      <td>0.6486</td>\n",
       "      <td>-0.0826</td>\n",
       "      <td>-11.2965%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        SYMBOL    LAST     CHG       %CHG\n",
       "0                                 AYROAYRO Inc  1.7900 -0.0200     -1.10%\n",
       "1  FFIEFaraday Future Intelligent Electric Inc  0.0945  0.0008   +0.8538%\n",
       "2                              FUVArcimoto Inc  0.6298  0.0099    +1.597%\n",
       "3                    MULNMullen Automotive Inc  8.0700 -1.0600    -11.61%\n",
       "4                                FSRFisker Inc  0.6486 -0.0826  -11.2965%"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_html(\"https://www.cnbc.com/quotes/GOEV?tab=profile\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e31201b",
   "metadata": {},
   "source": [
    "## 3.Internet Search by querry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5eeb17a",
   "metadata": {},
   "source": [
    "**Data required for Data analysis of canoo and it's peers is scraped by above methods**\n",
    "\n",
    "**This is for Demonstration, there also various advance ways to scrap the data using AI**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524f885c",
   "metadata": {},
   "source": [
    "### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78e0a662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from scrapy.selector import Selector\n",
    "from scrapy.http import HtmlResponse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31b79c8",
   "metadata": {},
   "source": [
    "### Creating a function to search Google and get relevant URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a17472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def google_search(query):\n",
    "    search_url = f\"https://www.google.com/search?q={'+'.join(query.split())}\"\n",
    "    response = requests.get(search_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    urls = [a['href'] for a in soup.find_all('a', href=True) if a['href'].startswith(\"http\")]\n",
    "    return urls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad98f4a5",
   "metadata": {},
   "source": [
    "#### 1st method - Creating function to scrape data from a URL using Scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5c9f3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scrape_with_scrapy(url):\n",
    "    # Scrapy setup\n",
    "    from scrapy.crawler import CrawlerProcess\n",
    "    import scrapy\n",
    "\n",
    "    class MySpider(scrapy.Spider):\n",
    "        name = 'myspider'\n",
    "\n",
    "        def start_requests(self):\n",
    "            yield scrapy.Request(url, self.parse)\n",
    "\n",
    "        def parse(self, response):\n",
    "            # We can write the detailed code for extracting tables, of nested data\n",
    "            # For demonstration, let's just extract the title of the page\n",
    "            yield {\n",
    "                'URL': response.url,\n",
    "                'Title': response.css('title::text').get()\n",
    "            }\n",
    "\n",
    "    process = CrawlerProcess(settings={\n",
    "        'USER_AGENT': 'Mozilla/5.0',\n",
    "        'LOG_ENABLED': False  # Disable logging for clarity\n",
    "    })\n",
    "\n",
    "    # Run the spider\n",
    "    data = []\n",
    "    process.crawl(MySpider)\n",
    "    process.start()\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98550f07",
   "metadata": {},
   "source": [
    "#### 2nd method - Creating function to scrape data from a URL using Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e44d6815",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scrape_with_selenium(url):\n",
    "    \n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "\n",
    "    # we can give here the web page tags so we can get the actual text data we want\n",
    "    # For demonstration, let's just extract the page title\n",
    "    title = driver.title\n",
    "\n",
    "    # Close the Selenium WebDriver\n",
    "    driver.quit()\n",
    "\n",
    "    return {'URL': url, 'Title': title}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5515d8b4",
   "metadata": {},
   "source": [
    "#### 3rd method - function to scrape data from a URL using Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8cada99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scrape_with_beautifulsoup(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    # For demonstration, let's just extract the page title\n",
    "    title = soup.title.string\n",
    "\n",
    "    return {'URL': url, 'Title': title}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd31171e",
   "metadata": {},
   "source": [
    "### Create function to save data to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "750a75f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_to_csv(data_list, filename):\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = data_list[0].keys()\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for data in data_list:\n",
    "            writer.writerow(data)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3156d744",
   "metadata": {},
   "source": [
    "### Main function which scrap the data and store in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de3da33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for: Gather information on Canoo's financial performance, including its revenue, profit margins, return on investment, and expense structure\n",
      "Scraping data from: https://www.google.com/preferences?hl=en-IN&fg=1&sa=X&ved=0ahUKEwiCxdT_t7qEAxXGzzgGHWGYDikQ5fUCCHs\n",
      "Scraping data from: https://policies.google.com/privacy?hl=en-IN&fg=1\n",
      "Scraping data from: https://policies.google.com/terms?hl=en-IN&fg=1\n",
      "Data saved to scraped_data.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "    queries = [\n",
    "        \"Gather information on Canoo's financial performance, including its revenue, profit margins, return on investment, and expense structure\"\n",
    "    ]\n",
    "    all_data = []\n",
    "\n",
    "    for query in queries:\n",
    "        print(f\"Searching for: {query}\")\n",
    "        urls = google_search(query)\n",
    "        for url in urls:\n",
    "            print(f\"Scraping data from: {url}\")\n",
    "            # Choose one of the scraping methods (Scrapy, Selenium, Beautiful Soup)\n",
    "            data = scrape_with_selenium(url)\n",
    "            # Add scraped data to the list\n",
    "            all_data.append(data)\n",
    "\n",
    "    # Save the scraped data to a CSV file\n",
    "    save_to_csv(all_data, \"scraped_data.csv\")\n",
    "    print(\"Data saved to scraped_data.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b89390",
   "metadata": {},
   "source": [
    "**After getting this Urls we can use power querry of advance excel, libraries like octoparse and other AI tools to scrap the large data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce6e67b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
